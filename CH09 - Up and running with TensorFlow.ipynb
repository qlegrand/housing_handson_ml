{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import StratifiedShuffleSplit as SSS\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data = housing.data\n",
    "housing_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.000e+00 8.220e+02]\n",
      " [2.000e+00 6.581e+03]\n",
      " [3.000e+00 7.236e+03]\n",
      " [4.000e+00 3.639e+03]\n",
      " [5.000e+00 1.423e+03]\n",
      " [6.000e+00 5.320e+02]\n",
      " [7.000e+00 1.890e+02]\n",
      " [8.000e+00 1.050e+02]\n",
      " [9.000e+00 5.000e+01]\n",
      " [1.000e+01 1.400e+01]\n",
      " [1.100e+01 4.900e+01]]\n"
     ]
    }
   ],
   "source": [
    "#train/test split method based on stratas\n",
    "housing_strat = housing_data.copy()\n",
    "housing_strat = np.c_[housing_strat,np.ceil(housing_data[:,0] / 1.5)]\n",
    "unique, counts = np.unique(housing_strat[:,8], return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)\n",
    "housing_strat = np.c_[housing_strat, housing.target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = SSS(n_splits = 1, test_size = 0.2, random_state = 42)\n",
    "for train_index, test_index in split.split(housing_strat, housing_strat[:,8]):\n",
    "    strat_train_set = housing_strat[train_index,:]\n",
    "    strat_test_set = housing_strat[test_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train_target, housing_test_target = strat_train_set[:,9], strat_test_set[:,9]\n",
    "housing_train_data, housing_test_data = strat_train_set[:,:9], strat_test_set[:,:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(housing_train_data)\n",
    "housing_train_data = scaler.transform(housing_train_data)\n",
    "housing_test_data = scaler.transform(housing_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = housing_train_data.shape\n",
    "m_test, n_test = housing_test_data.shape\n",
    "housing_train_data = np.c_[np.ones((m,1)), housing_train_data]\n",
    "housing_test_data = np.c_[np.ones((m_test,1)), housing_test_data]\n",
    "n_epoch = 1000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf.reset_default_graph()\\nX = tf.constant(housing_train_data, dtype = tf.float32, name = \"X\")\\ny = tf.constant(housing_train_target.reshape(-1,1), dtype = tf.float32, name = \"y\")\\ntheta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name = \"theta\")\\ny_pred = tf.matmul(X, theta, name = \"prediction\")\\nerror = y_pred - y\\nmse = tf.reduce_mean(tf.square(error), name = \"mse\")\\n#gradients = 2/m * tf.matmul(tf.transpose(X), error)\\n#gradients = tf.gradients(mse, [theta])[0]\\n#training_op = tf.assign(theta, theta - learning_rate*gradients)\\noptimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\\ntraining_op = optimizer.minimize(mse)\\ninit = tf.global_variables_initializer()'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''tf.reset_default_graph()\n",
    "X = tf.constant(housing_train_data, dtype = tf.float32, name = \"X\")\n",
    "y = tf.constant(housing_train_target.reshape(-1,1), dtype = tf.float32, name = \"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X, theta, name = \"prediction\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "#gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "#gradients = tf.gradients(mse, [theta])[0]\n",
    "#training_op = tf.assign(theta, theta - learning_rate*gradients)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "init = tf.global_variables_initializer()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with tf.Session() as sess:\\n    sess.run(init)\\n    for epoch in range(n_epoch):\\n        if epoch % 100 == 0:\\n            print(\"Epoch \", epoch, \" MSE = \", mse.eval())\\n        sess.run(training_op)\\n    best_theta = theta.eval()'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epoch):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch \", epoch, \" MSE = \", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(epoch, batch_index, batch_size, n_batches, X, y):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  # not shown in the book\n",
    "    indices = np.random.randint(m, size = batch_size)  # not shown\n",
    "    X_batch = X[indices, :] # not shown\n",
    "    y_batch = y[indices, :] # not shown\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = dt.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"./tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape = (None, n+1), name = \"X\")\n",
    "y = tf.placeholder(tf.float32, shape = (None, 1), name = \"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X, theta, name = \"prediction\")\n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  MSE =  5.133388\n",
      "Epoch  100  MSE =  0.53154534\n",
      "Epoch  200  MSE =  0.52904093\n",
      "Epoch  300  MSE =  0.53023237\n",
      "Epoch  400  MSE =  0.5274053\n",
      "Epoch  500  MSE =  0.5306007\n",
      "Epoch  600  MSE =  0.5288235\n",
      "Epoch  700  MSE =  0.5294174\n",
      "Epoch  800  MSE =  0.5289626\n",
      "Epoch  900  MSE =  0.5271695\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "n_batch = int(np.ceil(m / batch_size))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(n_epoch):\n",
    "        if e % 100 == 0:\n",
    "            save_path = saver.save(sess,\".\\my_model.ckpt\")\n",
    "            print(\"Epoch \", e, \" MSE = \", sess.run(mse, feed_dict = {X : housing_train_data, y : housing_train_target.reshape(-1,1)}))\n",
    "        for batch_index in range(n_batch):\n",
    "            X_batch, y_batch = fetch_batch(e, batch_index, batch_size, n_batch, housing_train_data, housing_train_target.reshape(-1,1))\n",
    "            sess.run(training_op, feed_dict = {X : X_batch, y : y_batch})\n",
    "            if batch_index % 10 == 0 :\n",
    "                summary_str = mse_summary.eval(feed_dict = {X : X_batch, y : y_batch})\n",
    "                step = e * n_batch + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \".\\my_model_final.ckpt\")\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\my_model_final.ckpt\n",
      "MSE test =  0.5166749\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \".\\my_model_final.ckpt\")\n",
    "    print(\"MSE test = \", sess.run(mse, feed_dict = {X : housing_test_data, y : housing_test_target.reshape(-1, 1)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/sub\n"
     ]
    }
   ],
   "source": [
    "print(error.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
